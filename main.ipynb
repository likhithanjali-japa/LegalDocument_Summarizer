{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fd92b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pdfplumber\n",
    "import PyPDF2\n",
    "import pytesseract\n",
    "import spacy\n",
    "import networkx as nx\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import Counter\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load a pre-trained Sentence-BERT model for embeddings\n",
    "bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "# === PDF Reading Functions ===\n",
    "\n",
    "def read_pdf_text(path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                content = page.extract_text()\n",
    "                if content:\n",
    "                    text += content + \" \"\n",
    "        if not text.strip():  # Fallback to PyPDF2 if pdfplumber fails to extract\n",
    "            with open(path, \"rb\") as file:\n",
    "                reader = PyPDF2.PdfReader(file)\n",
    "                for page in reader.pages:\n",
    "                    text += page.extract_text() or \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF with pdfplumber/PyPDF2: {e}\")\n",
    "        return \"\"  # Return empty string on error\n",
    "    return text.strip()\n",
    "\n",
    "def read_scanned_pdf_text(path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                img = page.to_image().original\n",
    "                text += pytesseract.image_to_string(img) + \" \"\n",
    "    except Exception as e:\n",
    "        print(f\"Error performing OCR with pytesseract: {e}\")\n",
    "        return \"\"  # Return empty string on error\n",
    "    return text.strip()\n",
    "\n",
    "# === Preprocessing ===\n",
    "\n",
    "def preprocess_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    processed_sentences = [\n",
    "        \" \".join([word.lower() for word in word_tokenize(sent) if word.isalnum() and word.lower() not in stop_words])\n",
    "        for sent in sentences\n",
    "    ]\n",
    "    return sentences, processed_sentences\n",
    "\n",
    "# ---\n",
    "## Summarization Techniques\n",
    "\n",
    "### Term Frequency Summarization\n",
    "\n",
    "def tf_summary(text, num_sentences=5):\n",
    "    sentences, processed = preprocess_text(text)\n",
    "    word_freq = {}\n",
    "\n",
    "    for sent in processed:\n",
    "        for word in word_tokenize(sent):\n",
    "            word_freq[word] = word_freq.get(word, 0) + 1\n",
    "\n",
    "    sentence_scores = []\n",
    "    for i, sent in enumerate(processed):\n",
    "        score = sum(word_freq.get(word, 0) for word in word_tokenize(sent))\n",
    "        sentence_scores.append((score, sentences[i]))\n",
    "\n",
    "    ranked = sorted(sentence_scores, reverse=True)\n",
    "    top = ranked[:num_sentences]\n",
    "    summary = \" \".join([s for _, s in top])\n",
    "    return summary, top\n",
    "\n",
    "### TextRank Summarization\n",
    "\n",
    "def textrank_summary(text, num_sentences=5):\n",
    "    sentences, _ = preprocess_text(text)\n",
    "    if not sentences:  # Handle empty sentences case\n",
    "        return \"\", []\n",
    "    if len(sentences) <= num_sentences:\n",
    "        return \" \".join(sentences), [(1.0, s) for s in sentences]\n",
    "\n",
    "    tfidf = TfidfVectorizer().fit_transform(sentences)\n",
    "    sim_matrix = (tfidf * tfidf.T).toarray()\n",
    "\n",
    "    graph = nx.from_numpy_array(sim_matrix)\n",
    "    scores = nx.pagerank(graph)\n",
    "\n",
    "    ranked = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "    top = ranked[:num_sentences]\n",
    "    summary = \" \".join([s for _, s in top])\n",
    "    return summary, top\n",
    "\n",
    "### NER-Based Summarization\n",
    "\n",
    "def ner_summary(text, num_sentences=5):\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentence_scores = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        doc_sent = nlp(sent)\n",
    "        # Assign weights to different entity types\n",
    "        score = sum({\n",
    "            \"PERSON\": 3,\n",
    "            \"ORG\": 2,\n",
    "            \"GPE\": 2,\n",
    "            \"LAW\": 3,\n",
    "            \"DATE\": 1,\n",
    "            \"MONEY\": 2,\n",
    "            \"LOC\": 1,\n",
    "            \"EVENT\": 2\n",
    "        }.get(ent.label_, 0) for ent in doc_sent.ents)\n",
    "\n",
    "        sentence_scores.append((score, sent))\n",
    "\n",
    "    ranked = sorted(sentence_scores, reverse=True)\n",
    "    top = ranked[:num_sentences]\n",
    "    summary = \" \".join([s for _, s in top])\n",
    "    return summary, top\n",
    "\n",
    "### BERT Extractive Summarization\n",
    "\n",
    "def bert_extractive_summary(text, num_sentences=5):\n",
    "    \"\"\"\n",
    "    Performs extractive summarization using BERT sentence embeddings.\n",
    "    Sentences are ranked by their cosine similarity to the document's overall embedding.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "        num_sentences (int): The number of sentences to include in the summary.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated summary.\n",
    "        list: A list of tuples (similarity_score, sentence_text) for the top sentences.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    if not sentences:\n",
    "        return \"\", []\n",
    "\n",
    "    # Get embeddings for all sentences\n",
    "    sentence_embeddings = bert_model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "    # Get embedding for the entire document\n",
    "    document_embedding = bert_model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "    bert_scores = []\n",
    "    for i, sent_embedding in enumerate(sentence_embeddings):\n",
    "        # Calculate cosine similarity between sentence embedding and document embedding\n",
    "        similarity = cosine_similarity(sent_embedding.cpu().numpy().reshape(1, -1),\n",
    "                                       document_embedding.cpu().numpy().reshape(1, -1))[0][0]\n",
    "        bert_scores.append((similarity, sentences[i]))\n",
    "\n",
    "    # Rank sentences based on their BERT similarity score in descending order\n",
    "    ranked_sentences = sorted(bert_scores, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Select the top N sentences for the summary\n",
    "    top_summary_sentences_with_scores = ranked_sentences[:num_sentences]\n",
    "\n",
    "    # Combine the summary sentences. It's often good practice to try to preserve original document order\n",
    "    # for the selected sentences for readability, even if they were ranked by score.\n",
    "    original_sentence_map = {sentence: idx for idx, sentence in enumerate(sentences)}\n",
    "    summary_texts_ordered = sorted(top_summary_sentences_with_scores, key=lambda x: original_sentence_map.get(x[1], float('inf')))\n",
    "    summary = \" \".join([s for _, s in summary_texts_ordered])\n",
    "\n",
    "    return summary, top_summary_sentences_with_scores\n",
    "\n",
    "# === Evaluation Metrics ===\n",
    "\n",
    "def calculate_accuracy(full_text, summary):\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity (using TF-IDF) between the full text and the summary.\n",
    "    This provides a measure of content overlap.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer().fit([full_text, summary])\n",
    "    vectors = vectorizer.transform([full_text, summary])\n",
    "    similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# ---\n",
    "## Main Execution\n",
    "\n",
    "def generate_overall_summary(text, num_sentences=5):\n",
    "    \"\"\"\n",
    "    Generates an overall summary by combining the results of different summarization methods.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "        num_sentences (int): The desired number of sentences in the final summary.\n",
    "\n",
    "    Returns:\n",
    "        str: The overall summary.\n",
    "        list: A list of tuples (similarity_score, sentence_text) for the top sentences.\n",
    "    \"\"\"\n",
    "\n",
    "    tf_summary_text, _ = tf_summary(text, num_sentences=num_sentences)\n",
    "    textrank_summary_text, _ = textrank_summary(text, num_sentences=num_sentences)\n",
    "    ner_summary_text, _ = ner_summary(text, num_sentences=num_sentences)\n",
    "    bert_summary_text, _ = bert_extractive_summary(text, num_sentences=num_sentences)\n",
    "\n",
    "    # Combine all sentences from different summaries\n",
    "    all_summary_sentences = sent_tokenize(tf_summary_text) + \\\n",
    "                            sent_tokenize(textrank_summary_text) + \\\n",
    "                            sent_tokenize(ner_summary_text) + \\\n",
    "                            sent_tokenize(bert_summary_text)\n",
    "\n",
    "    # Remove duplicate sentences\n",
    "    unique_sentences = list(dict.fromkeys(all_summary_sentences))\n",
    "\n",
    "    # Rank the unique sentences based on BERT similarity to the original document\n",
    "    sentence_embeddings = bert_model.encode(unique_sentences, convert_to_tensor=True)\n",
    "    document_embedding = bert_model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "    sentence_scores = []\n",
    "    for i, sent_embedding in enumerate(sentence_embeddings):\n",
    "        similarity = cosine_similarity(sent_embedding.cpu().numpy().reshape(1, -1),\n",
    "                                       document_embedding.cpu().numpy().reshape(1, -1))[0][0]\n",
    "        sentence_scores.append((similarity, unique_sentences[i]))\n",
    "\n",
    "    ranked_sentences = sorted(sentence_scores, key=lambda x: x[0], reverse=True)\n",
    "    top_sentences_with_scores = ranked_sentences[:num_sentences]  # Keep scores\n",
    "\n",
    "    # Sort the selected sentences by their original order in the document\n",
    "    original_sentences = sent_tokenize(text)\n",
    "    original_sentence_map = {sentence: idx for idx, sentence in enumerate(original_sentences)}\n",
    "    final_summary_sentences = sorted(top_sentences_with_scores, key=lambda x: original_sentence_map.get(x[1], float('inf')))\n",
    "\n",
    "    # Combine the top sentences into a coherent summary\n",
    "    overall_summary = \" \".join([sentence for _, sentence in final_summary_sentences]) # Extract just the sentences\n",
    "\n",
    "    return overall_summary, final_summary_sentences # Return the sentences with scores\n",
    "\n",
    "def count_sentence_occurrences(text, num_sentences=5):\n",
    "    \"\"\"\n",
    "    Counts the occurrences of sentences in the summaries generated by different methods.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "        num_sentences (int): The number of sentences to include in each summary.\n",
    "\n",
    "    Returns:\n",
    "        Counter: A Counter object containing the sentences and their occurrences.\n",
    "    \"\"\"\n",
    "    tf_summary_text, _ = tf_summary(text, num_sentences=num_sentences)\n",
    "    textrank_summary_text, _ = textrank_summary(text, num_sentences=num_sentences)\n",
    "    ner_summary_text, _ = ner_summary(text, num_sentences=num_sentences)\n",
    "    bert_summary_text, _ = bert_extractive_summary(text, num_sentences=num_sentences)\n",
    "\n",
    "    all_summary_sentences = sent_tokenize(tf_summary_text) + \\\n",
    "                            sent_tokenize(textrank_summary_text) + \\\n",
    "                            sent_tokenize(ner_summary_text) + \\\n",
    "                            sent_tokenize(bert_summary_text)\n",
    "\n",
    "    sentence_counts = Counter(all_summary_sentences)\n",
    "    return sentence_counts\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\japal\\OneDrive\\Documents\\laxmi_narasimha.pdf\"\n",
    "\n",
    "# Load PDF\n",
    "document_text = read_pdf_text(file_path)\n",
    "if not document_text.strip():\n",
    "    print(\"PDF is empty or could not be read. Attempting OCR for scanned PDF...\")\n",
    "    document_text = read_scanned_pdf_text(file_path)\n",
    "\n",
    "if not document_text.strip():\n",
    "    print(\"Could not extract text from PDF. Please ensure the PDF is valid and readable.\")\n",
    "else:\n",
    "    # Generate Summaries\n",
    "    tf_summary_text, tf_scored = tf_summary(document_text, num_sentences=5)\n",
    "    textrank_summary_text, textrank_scored = textrank_summary(document_text, num_sentences=5)\n",
    "    ner_summary_text, ner_scored = ner_summary(document_text, num_sentences=5)\n",
    "    bert_summary_text, bert_scored = bert_extractive_summary(document_text, num_sentences=5)\n",
    "\n",
    "    # Calculate Accuracy Scores\n",
    "    tf_acc = calculate_accuracy(document_text, tf_summary_text)\n",
    "    tr_acc = calculate_accuracy(document_text, textrank_summary_text)\n",
    "    ner_acc = calculate_accuracy(document_text, ner_summary_text)\n",
    "    bert_acc = calculate_accuracy(document_text, bert_summary_text)\n",
    "\n",
    "    # ---\n",
    "    ## Output Results\n",
    "    \n",
    "\n",
    "    print(\"\\n\" + \"=\"*10 + \" Term Frequency Summary with Scores \" + \"=\"*10 + \"\\n\")\n",
    "    for score, sent in tf_scored:\n",
    "        print(f\"[Score: {score}] {sent.strip()}\")\n",
    "    print(\"\\n*TF Summary:*\\n\", tf_summary_text)\n",
    "    print(f\"\\n*TF Cosine Similarity:* {tf_acc:.4f} ({tf_acc * 100:.2f}%)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*10 + \" TextRank Summary with Scores \" + \"=\"*10 + \"\\n\")\n",
    "    for score, sent in textrank_scored:\n",
    "        print(f\"[Score: {score:.4f}] {sent.strip()}\")\n",
    "    print(\"\\n*TextRank Summary:*\\n\", textrank_summary_text)\n",
    "    print(f\"\\n*TextRank Cosine Similarity:* {tr_acc:.4f} ({tr_acc * 100:.2f}%)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*10 + \" NER Summary with Scores \" + \"=\"*10 + \"\\n\")\n",
    "    for score, sent in ner_scored:\n",
    "        print(f\"[Score: {score}] {sent.strip()}\")\n",
    "    print(\"\\n*NER Summary:*\\n\", ner_summary_text)\n",
    "    print(f\"\\n*NER Cosine Similarity:* {ner_acc:.4f} ({ner_acc * 100:.2f}%)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*10 + \" BERT Extractive Summary with Scores \" + \"=\"*10 + \"\\n\")\n",
    "    for score, sent in bert_scored:\n",
    "        print(f\"[BERT Similarity: {score:.4f}] {sent.strip()}\")\n",
    "    print(\"\\n*BERT Summary:*\\n\", bert_summary_text)\n",
    "    print(f\"\\n*BERT Cosine Similarity (TF-IDF based):* {bert_acc:.4f} ({bert_acc * 100:.2f}%)\")\n",
    "\n",
    "    # Generate and print the overall summary\n",
    "    overall_summary, important_sentences = generate_overall_summary(document_text, num_sentences=5)\n",
    "    print(\"\\n\" + \"=\"*10 + \" Overall Summary \" + \"=\"*10 + \"\\n\")\n",
    "    print(overall_summary)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*10 + \" Important Sentences with Scores \" + \"=\"*10 + \"\\n\")\n",
    "    for score, sent in important_sentences:\n",
    "        print(f\"[BERT Similarity: {score:.4f}] {sent.strip()}\")\n",
    "\n",
    "    # Count sentence occurrences\n",
    "    sentence_counts = count_sentence_occurrences(document_text, num_sentences=5)\n",
    "    most_common_sentences = sentence_counts.most_common()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*10 + \" Most Frequently Occurring Sentences \" + \"=\"*10 + \"\\n\")\n",
    "    for sentence, count in most_common_sentences:\n",
    "        print(f\"[Count: {count}] {sentence.strip()}\")\n",
    "\n",
    "    # Find sentences in the overall summary that are also among the most frequent\n",
    "    overall_summary_sentences = sent_tokenize(overall_summary)\n",
    "    most_frequent_in_summary = [\n",
    "        (sentence, count) for sentence, count in most_common_sentences if sentence in overall_summary_sentences\n",
    "    ]\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 10 + \" Important and Most Frequent Sentences from All Methods \" + \"=\" * 10 + \"\\n\")\n",
    "    if most_frequent_in_summary:\n",
    "        for sentence, count in most_frequent_in_summary:\n",
    "            print(f\"[Count: {count}] {sentence.strip()}\")\n",
    "    else:\n",
    "        print(\"No sentences were found to be both in the overall summary and among the most frequent.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
